{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1ca073-9a73-4d6f-8866-3be67e45e006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "data4 = pd.read_csv(\"bank-additional-full.csv\", sep=\";\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae2fd24-0739-4f60-a5fa-98901fde6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Ensure consistency across datasets\n",
    "common_columns = list(set(data4.columns))\n",
    "combined_data = pd.concat(\n",
    "    [data4[common_columns]],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = combined_data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {col: LabelEncoder() for col in categorical_cols}\n",
    "for col in categorical_cols:\n",
    "    combined_data[col] = label_encoders[col].fit_transform(combined_data[col])\n",
    "\n",
    "# Separate features and target\n",
    "X = combined_data.drop(columns=[\"y\"])\n",
    "y = combined_data[\"y\"]\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9612989e-815d-4bac-80ad-fca0b49b24ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step\n",
      "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step\n",
      "Stacked Model Accuracy: 0.9134094035769199\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     10968\n",
      "           1       0.64      0.54      0.58      1389\n",
      "\n",
      "    accuracy                           0.91     12357\n",
      "   macro avg       0.79      0.75      0.77     12357\n",
      "weighted avg       0.91      0.91      0.91     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- Neural Network Training ----\n",
    "nn_model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Define the input layer with the input shape\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "nn_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "# Neural Network predictions\n",
    "nn_preds_train = nn_model.predict(X_train)\n",
    "nn_preds_test = nn_model.predict(X_test)\n",
    "\n",
    "# ---- Random Forest Training ----\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest predictions\n",
    "rf_preds_train = rf_model.predict_proba(X_train)[:, 1]\n",
    "rf_preds_test = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ---- Stacking (Combining Outputs) ----\n",
    "stack_train = np.column_stack((nn_preds_train, rf_preds_train))\n",
    "stack_test = np.column_stack((nn_preds_test, rf_preds_test))\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(stack_train, y_train)\n",
    "\n",
    "# Final predictions\n",
    "final_preds = meta_model.predict(stack_test)\n",
    "\n",
    "# ---- Evaluation ----\n",
    "print(\"Stacked Model Accuracy:\", accuracy_score(y_test, final_preds))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8723a6-2472-43e7-a387-86fe2eef6a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6cfd568-2df6-4f5a-802e-ee14d1ecae19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8762 - loss: 0.2810\n",
      "Epoch 2/10\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.1959\n",
      "Epoch 3/10\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.1888\n",
      "Epoch 4/10\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.1830\n",
      "Epoch 5/10\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.1799\n",
      "Epoch 6/10\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9173 - loss: 0.1801\n",
      "Epoch 7/10\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.1733\n",
      "Epoch 8/10\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.1741\n",
      "Epoch 9/10\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9224 - loss: 0.1688\n",
      "Epoch 10/10\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.1693\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step\n",
      "Random Forest Accuracy: 0.9127215343529983\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      7303\n",
      "           1       0.64      0.51      0.57       935\n",
      "\n",
      "    accuracy                           0.91      8238\n",
      "   macro avg       0.79      0.74      0.76      8238\n",
      "weighted avg       0.91      0.91      0.91      8238\n",
      "\n",
      "Neural Network Accuracy: 0.9095654285020636\n",
      "Neural Network Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      7303\n",
      "           1       0.60      0.59      0.60       935\n",
      "\n",
      "    accuracy                           0.91      8238\n",
      "   macro avg       0.78      0.77      0.77      8238\n",
      "weighted avg       0.91      0.91      0.91      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# Handle categorical variables using Label Encoding (for simplicity)\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('y', axis=1)  # 'y' is the target column\n",
    "y = df['y']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 1. Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 2. Neural Network Model\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "nn_model.add(Dense(32, activation='relu'))\n",
    "nn_model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
    "\n",
    "nn_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "nn_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "nn_pred = (nn_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Evaluation - Random Forest\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_report = classification_report(y_test, rf_pred)\n",
    "\n",
    "# Evaluation - Neural Network\n",
    "nn_accuracy = accuracy_score(y_test, nn_pred)\n",
    "nn_report = classification_report(y_test, nn_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
    "print(f\"Random Forest Classification Report:\\n{rf_report}\")\n",
    "print(f\"Neural Network Accuracy: {nn_accuracy}\")\n",
    "print(f\"Neural Network Classification Report:\\n{nn_report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4137c9-73d4-4035-bc75-1eab19425a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
